# Action-Recognition
CMSC726 - Machine Learning in UMD

### Dataset
Download the following files and put them in to folder *data/*.
1. KTH dataset: http://www.nada.kth.se/cvap/actions/
There are 6 categories: walking, jogging, running, boxing, handwaving, handclapping. Each category has its own folder of videos, so there are 6 folders: *data/walking*, *data/jogging*, ...
2. Preprocessed data for the SVM baseline: https://drive.google.com/open?id=0B0qJbmmIVAJIYWtxZE1kbXg3WHM. Download these if you don't want to run the code to generate them.
This includes:
    * Human dectected bounding box using [Histogram of Gradients](https://www.learnopencv.com/histogram-of-oriented-gradients): files prefixed with *human_detected_*, can be generated by running *code/human_detection.py*.
    * [SIFT](http://www.aishack.in/tutorials/sift-scale-invariant-feature-transform-features/) feature extraction for each human bounding box: files prefixed with *sift_*, can be generated by running *code/feature_extraction.py*.